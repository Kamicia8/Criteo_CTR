{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c653b13f-df4d-46cb-93cf-07da24fb2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97566ae8-c457-4633-b878-eb8cb531b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a2d3e5452553:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f434cfba1d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.local.dir\", \"spark\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1a26aeb-e784-4aa6-a1c4-31d20f4e1940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:\n",
      "2000000\n",
      "\n",
      "Column Names:\n",
      "['Label', 'I1', 'I2', 'I4', 'I5', 'I6', 'I7', 'I10', 'I11', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9', 'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19', 'C20', 'C21', 'C23', 'C24', 'C25', 'C26']\n"
     ]
    }
   ],
   "source": [
    "data_cleaned = spark.read.parquet(\"dataset_no_missing_values\")\n",
    "data_cleaned = data_cleaned.repartition(400)\n",
    "\n",
    "print(\"Number of rows:\")\n",
    "print(data_cleaned.count())\n",
    "\n",
    "print(\"\\nColumn Names:\")\n",
    "print(data_cleaned.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce5b717-3fc9-4fb3-b1a0-e355c06d39bb",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe1341a-737b-44b3-a93d-8b2bad39f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d02560-0497-4bb3-b8e0-787846b6502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [col for col in data_cleaned.columns if col != \"Label\"]  \n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", \n",
    "                             outputCol=\"scaledFeatures\",\n",
    "                             withStd=True, \n",
    "                             withMean=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e764e46-6897-4474-ac0b-38c52c769608",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_pca = Pipeline(stages=[assembler, scaler])\n",
    "scaler_model = pipeline_pca.fit(data_cleaned)\n",
    "scaled_data= scaler_model.transform(data_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f212b63-94b7-45b3-8204-90017153eeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(numeric_cols)\n",
    "pca_model_selection= PCA(k=num_features, inputCol=\"scaledFeatures\", outputCol=\"pcaFeatures\").fit(scaled_data)\n",
    "\n",
    "explained_variance = pca_model_selection.explainedVariance\n",
    "cumulative_variance = []\n",
    "total_variance = 0.0\n",
    "for variance in explained_variance:\n",
    "    total_variance += float(variance)\n",
    "    cumulative_variance.append(total_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f560f78-9cc4-4a6b-94a6-e4dbfa7576f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 50% — Components: 12, Cumulative Variance: 0.5008\n",
      "Threshold: 70% — Components: 19, Cumulative Variance: 0.7041\n",
      "Threshold: 80% — Components: 23, Cumulative Variance: 0.8101\n",
      "Threshold: 90% — Components: 27, Cumulative Variance: 0.9092\n",
      "Threshold: 95% — Components: 30, Cumulative Variance: 0.9653\n"
     ]
    }
   ],
   "source": [
    "variance_thresholds = [0.50, 0.70, 0.80, 0.90, 0.95]\n",
    "\n",
    "cumulative_variance = []\n",
    "total = 0.0\n",
    "for variance in explained_variance:\n",
    "    total += float(variance)\n",
    "    cumulative_variance.append(total)\n",
    "\n",
    "for threshold in variance_thresholds:\n",
    "    try:\n",
    "        best_k = next(i + 1 for i, cum_var in enumerate(cumulative_variance) if cum_var >= threshold)\n",
    "        print(f\"Threshold: {int(threshold * 100)}% — Components: {best_k}, Cumulative Variance: {cumulative_variance[best_k - 1]:.4f}\")\n",
    "    except StopIteration:\n",
    "        print(f\"Threshold: {int(threshold * 100)}% — No sufficient components found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
